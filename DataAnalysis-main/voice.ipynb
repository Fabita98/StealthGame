{
 "cells": [
  {
   "cell_type": "code",
   "id": "2492342f2b08151f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import os\n",
    "import audeer\n",
    "import audonnx\n",
    "import audinterface\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "\n",
    "model_root = 'voice/model'\n",
    "cache_root = 'voice/cache'\n",
    "test_root = 'G:/Il mio Drive/Test'\n",
    "test_root = 'mnt/g/Il mio Drive/Test'\n",
    "recordings_root = test_root + '/S{0}'\n",
    "testers = sorted([int(x[1:]) for x in os.listdir(test_root) if x.startswith('S')])\n",
    "\n",
    "audeer.mkdir(cache_root)\n",
    "\n",
    "\n",
    "def cache_path(file):\n",
    "    return os.path.join(cache_root, file)\n",
    "\n",
    "\n",
    "url = 'https://zenodo.org/record/6221127/files/w2v2-L-robust-12.6bc4a7fd-1.1.0.zip'\n",
    "dst_path = cache_path('model.zip')\n",
    "if not os.path.exists(dst_path):\n",
    "    audeer.download_url(url, dst_path, verbose=True)\n",
    "\n",
    "if not os.path.exists(model_root):\n",
    "    audeer.extract_archive(dst_path, model_root, verbose=True)\n",
    "\n",
    "model = audonnx.load(model_root)\n",
    "\n",
    "sampling_rate = 16000\n",
    "interface = audinterface.Feature(\n",
    "    model.labels('logits'),\n",
    "    process_func=model,\n",
    "    process_func_args={\n",
    "        'outputs': 'logits'\n",
    "    },\n",
    "    sampling_rate=sampling_rate,\n",
    "    resample=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "def get_recordings_root(tester_id, processed=False):\n",
    "    folder = 'ProcessedRecordings' if processed else 'Recordings'\n",
    "    return recordings_root.format(tester_id) + \"/\" + folder\n",
    "\n",
    "\n",
    "def analize_audios(tester, trimmed, replace=False, ignore_silenced=True, processed=False):\n",
    "    audio_root = get_recordings_root(tester)\n",
    "    output_root = recordings_root.format(tester)\n",
    "    # check if the file already exists\n",
    "    if not replace:\n",
    "        f = os.path.join(output_root, f'voice{\"_trimmed\" if trimmed else \"\"}{\"_processed\" if processed else \"\"}.csv')\n",
    "        if os.path.exists(f):\n",
    "            print(f'File {\"(trimmed)\" if trimmed else \"\"} already exists, skipping')\n",
    "            return\n",
    "\n",
    "    audio_files = [x for x in os.listdir(audio_root) if x.endswith('.wav') and not 'silenced' in x]\n",
    "    audio_files.sort()\n",
    "\n",
    "    if trimmed:\n",
    "        audio_files = [y for y in audio_files if 'trimmed' in y]\n",
    "    else:\n",
    "        audio_files = [y for y in audio_files if 'trimmed' not in y]\n",
    "    data = {\n",
    "        'start': [],\n",
    "        'end': [],\n",
    "        'arousal': [],\n",
    "        'valence': [],\n",
    "        'dominance': []\n",
    "    }\n",
    "    audio_files_size = len(audio_files)\n",
    "    print('Analysing {0} files'.format(audio_files_size))\n",
    "    silenced = 0\n",
    "    for i, record in enumerate(audio_files):\n",
    "        path = os.path.join(audio_root, record)\n",
    "        tmp = record.split(\"_\")\n",
    "        start = int(tmp[0])\n",
    "        end = int(tmp[1].replace('.wav', ''))\n",
    "        if ignore_silenced and AudioSegment.from_wav(path).dBFS < -40:\n",
    "            print(\"Ignoring file {0} ({1}/{2})\".format(record, i + 1, audio_files_size))\n",
    "            silenced += 1\n",
    "            continue\n",
    "        else:\n",
    "            print('Analysing {0} ({1}/{2})'.format(record, i + 1, audio_files_size))\n",
    "        try:\n",
    "            res = interface.process_file(path).round(2)\n",
    "            ar = res.iloc[0][\"arousal\"]\n",
    "            va = res.iloc[0][\"valence\"]\n",
    "            do = res.iloc[0][\"dominance\"]\n",
    "            data['start'].append(start)\n",
    "            data['end'].append(end)\n",
    "            data['arousal'].append(ar)\n",
    "            data['valence'].append(va)\n",
    "            data['dominance'].append(do)\n",
    "        except:\n",
    "            print(\"Error processing file {0}\".format(path))\n",
    "            data['start'].append(start)\n",
    "            data['end'].append(end)\n",
    "            data['arousal'].append(np.nan)\n",
    "            data['valence'].append(np.nan)\n",
    "            data['dominance'].append(np.nan)\n",
    "            continue\n",
    "\n",
    "    path = os.path.join(output_root, f'voice{\"_trimmed\" if trimmed else \"\"}{\"_processed\" if processed else \"\"}.csv')\n",
    "    pd.DataFrame(data).to_csv(path, index=False)\n",
    "    if ignore_silenced:\n",
    "        print(\"Silenced files: {0}\".format(silenced))\n",
    "    print(\"done!\")\n",
    "\n",
    "\n",
    "def rename_silenced_files(tester):\n",
    "    audio_root = get_recordings_root(tester)\n",
    "    audio_files = [x for x in os.listdir(audio_root) if x.endswith('.wav')]\n",
    "    audio_files.sort()\n",
    "    for i, record in enumerate(audio_files):\n",
    "        path = os.path.join(audio_root, record)\n",
    "        if AudioSegment.from_wav(path).dBFS < -30:\n",
    "            print(\"Renaming file {0}\".format(record))\n",
    "            os.rename(path, path.replace('.wav', '_silenced.wav'))\n",
    "\n",
    "\n",
    "def restore_silenced_files(tester):\n",
    "    audio_root = get_recordings_root(tester)\n",
    "    audio_files = [x for x in os.listdir(audio_root) if x.endswith('_silenced.wav')]\n",
    "    audio_files.sort()\n",
    "    for i, record in enumerate(audio_files):\n",
    "        path = os.path.join(audio_root, record)\n",
    "        print(\"Restoring file {0}\".format(record))\n",
    "        os.rename(path, path.replace('_silenced.wav', '.wav'))\n",
    "\n",
    "\n",
    "def analize_all_testers(replace=True, processed=False):\n",
    "    print(\"Testers: {0}\".format(testers))\n",
    "    for tester in testers:\n",
    "        print(\"Analyzing Tester {0}\".format(tester))\n",
    "        analize_audios(tester, trimmed=False, replace=replace, ignore_silenced=True)\n",
    "        analize_audios(tester, trimmed=True, replace=replace, ignore_silenced=True)\n",
    "\n",
    "#analize_audios(101, trimmed=False, replace=True, remove_silenced=True)\n",
    "#rename_silenced_files(101)\n",
    "#analize_audios(101, trimmed=False, replace=True, ignore_silenced=True)\n",
    "#restore_silenced_files(101)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "analize_all_testers(replace=False, processed=True)",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fps = 50\n",
    "trimmed = False\n",
    "\n",
    "\n",
    "def plot_data(data_arr, title):\n",
    "    plt.figure()\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Arousal')\n",
    "    plt.title(title)\n",
    "    #plt.xticks(np.linspace(0, (max(d.keys()) - min(d.keys())) / 1000, 10))\n",
    "    plt.plot(list(data_arr.keys()), list(data_arr.values()))\n",
    "\n",
    "\n",
    "def get_checkpoint_dictionary(tester):\n",
    "    data_tracker = pd.read_csv(test_root + '/S{0}/S{0}.csv'.format(tester), skiprows=1, sep=';')\n",
    "    #print(data_tracker[\"LastCheckpoint\"])\n",
    "    init_time = data_tracker[\"timestampStartFixedMillisecond\"].min()\n",
    "    timestamps = data_tracker[\"timestampStartFixedMillisecond\"] - init_time\n",
    "    checkpointsDictionary = {key / 1000: val for key, val in zip(timestamps, data_tracker[\"LastCheckpoint\"]) if\n",
    "                             not pd.isna(val)}\n",
    "    unique_checkpoints = dict()\n",
    "    for timestamp, checkpoint in checkpointsDictionary.items():\n",
    "        if checkpoint not in unique_checkpoints.values():\n",
    "            unique_checkpoints[timestamp] = checkpoint\n",
    "\n",
    "    print(unique_checkpoints)\n",
    "    return unique_checkpoints\n",
    "\n",
    "\n",
    "def plot_data_with_dante(tester, separateCheckpoints=True):\n",
    "    voice_path = test_root + f'/S{tester}/voice{\"_trimmed\" if trimmed else \"\"}_processed.csv'\n",
    "    df = pd.read_csv(voice_path)\n",
    "    dante = pd.read_csv(test_root + '/S{0}/stress.csv'.format(tester), sep=';')\n",
    "\n",
    "    min_time = df['start'].min()\n",
    "    max_time = df['end'].max()\n",
    "\n",
    "    print(f\"Min time: {min_time}, Max time: {max_time}\")\n",
    "    print(f\"Total time: {int((max_time - min_time) / 1000 / 60)}:{int((max_time - min_time) / 1000 % 60)} min\")\n",
    "\n",
    "    data = np.arange(0, max_time - min_time, 1000 / fps)\n",
    "    d = {key: 0 for key in data}\n",
    "    #remove last from df\n",
    "    df = df[:-1]\n",
    "\n",
    "    for row in df.index:\n",
    "        start = df['start'][row] - min_time\n",
    "        end = df['end'][row] - min_time\n",
    "        ar = df['arousal'][row]\n",
    "        for k, v in d.items():\n",
    "            if start < k < end:\n",
    "                if d[k] != 0:\n",
    "                    print(\"Overlapping data at {0}\".format(k))\n",
    "                d[k] = ar\n",
    "\n",
    "    #print(\"0 values: {0}\".format(np.sum(np.array(list(d.values())) == 0)))\n",
    "    d = {k / 1000: v if v != 0 else np.nan for k, v in d.items()}\n",
    "    tot_time = (max_time - min_time) / 1000\n",
    "\n",
    "    plt.plot(dante['TimeStamp'], (dante['Value'] + 1) / 2)\n",
    "    plt.plot(list(d.keys()), list(d.values()), color='red')\n",
    "    plt.title('Tester {0}'.format(tester))\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylim((0, 1))\n",
    "    plt.ylabel('Value')\n",
    "    plt.show()\n",
    "\n",
    "    if (separateCheckpoints):\n",
    "        #split for each checkpoint\n",
    "        checkpoints = get_checkpoint_dictionary(tester)\n",
    "        last_t = 0\n",
    "        for time, ckpt in checkpoints.items():\n",
    "            #get data between 0 and time\n",
    "            dante_part = dante[dante['TimeStamp'] < time]\n",
    "            dante_part = dante_part[dante_part['TimeStamp'] > last_t]\n",
    "            data_part = {k: v for k, v in d.items() if last_t < k < time}\n",
    "            plt.plot(dante_part['TimeStamp'], (dante_part['Value'] + 1) / 2)\n",
    "            plt.plot(list(data_part.keys()), list(data_part.values()), color='red')\n",
    "            plt.title('Tester {0} - {1}'.format(tester, ckpt))\n",
    "            plt.xlabel('Time')\n",
    "            plt.ylim((0, 1))\n",
    "            plt.ylabel('Value')\n",
    "            plt.show()\n",
    "            last_t = time\n",
    "            #dante_arousal = (dante_part['Value'] + 1)/2\n",
    "            #print(\"Correlation between stress and voice data: {0}\\n\".format(dante_arousal.corr(pd.Series(list(data_part.values())))))\n",
    "\n",
    "    dante_arousal = (dante['Value'] + 1) / 2\n",
    "    print(\"Correlation between stress and voice data: {0}\\n\".format(dante_arousal.corr(pd.Series(list(d.values())))))\n",
    "\n",
    "\n",
    "#for tester in testers:\n",
    "#plot_data_with_dante(tester)\n",
    "plot_data_with_dante(4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T11:55:40.269400400Z",
     "start_time": "2024-03-30T11:55:27.411974600Z"
    }
   },
   "id": "40c0a5318f3decf4",
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Correlation between trimmed and untrimmed data\n",
    "t = 18\n",
    "df1 = pd.read_csv('G:\\My Drive\\Test\\S{0}\\\\voice.csv'.format(t))\n",
    "df2 = pd.read_csv('G:\\My Drive\\Test\\S{0}\\\\voice_processed.csv'.format(t))\n",
    "\n",
    "print(\"Correlation between trimmed and untrimmed data\")\n",
    "print(\"Arousal: {0}\".format(df1['arousal'].corr(df2['arousal'])))\n",
    "print(\"Valence: {0}\".format(df1['valence'].corr(df2['valence'])))\n",
    "print(\"Dominance: {0}\".format(df1['dominance'].corr(df2['dominance'])))\n",
    "\n",
    "plt.scatter(df1['arousal'], df2['arousal'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8eef848a8ceee9af",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
